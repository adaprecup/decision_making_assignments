{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:13:16.573239Z",
     "start_time": "2025-05-19T12:13:16.565070Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import openpyxl"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:13:16.591101Z",
     "start_time": "2025-05-19T12:13:16.587571Z"
    }
   },
   "source": [
    "# make sure pandas is version 1.0 or higher\n",
    "# make sure networkx is verion 2.4 or higher\n",
    "print(pd.__version__)\n",
    "print(nx.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.3\n",
      "3.4.2\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-19T12:16:44.013780Z",
     "start_time": "2025-05-19T12:16:44.009726Z"
    }
   },
   "source": [
    "from ema_workbench import (\n",
    "    Model,\n",
    "    Policy,\n",
    "    ema_logging,\n",
    "    SequentialEvaluator,\n",
    "    MultiprocessingEvaluator,\n",
    ")\n",
    "from dike_model_function import DikeNetwork  # @UnresolvedImport\n",
    "from problem_formulation import get_model_for_problem_formulation, sum_over, sum_over_time\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:16:45.736790Z",
     "start_time": "2025-05-19T12:16:45.593240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "# choose problem formulation number, between 0-5\n",
    "# each problem formulation has its own list of outcomes\n",
    "dike_model, planning_steps = get_model_for_problem_formulation(4)"
   ],
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'xlrd'. Install xlrd >= 2.0.1 for xls Excel support Use pip or conda to install xlrd.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~/decision_making_assignments/venv/lib/python3.13/site-packages/pandas/compat/_optional.py:135\u001B[39m, in \u001B[36mimport_optional_dependency\u001B[39m\u001B[34m(name, extra, errors, min_version)\u001B[39m\n\u001B[32m    134\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m135\u001B[39m     module = \u001B[43mimportlib\u001B[49m\u001B[43m.\u001B[49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    136\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/importlib/__init__.py:88\u001B[39m, in \u001B[36mimport_module\u001B[39m\u001B[34m(name, package)\u001B[39m\n\u001B[32m     87\u001B[39m         level += \u001B[32m1\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m88\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:1387\u001B[39m, in \u001B[36m_gcd_import\u001B[39m\u001B[34m(name, package, level)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:1360\u001B[39m, in \u001B[36m_find_and_load\u001B[39m\u001B[34m(name, import_)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:1324\u001B[39m, in \u001B[36m_find_and_load_unlocked\u001B[39m\u001B[34m(name, import_)\u001B[39m\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'xlrd'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      1\u001B[39m ema_logging.log_to_stderr(ema_logging.INFO)\n\u001B[32m      3\u001B[39m \u001B[38;5;66;03m# choose problem formulation number, between 0-5\u001B[39;00m\n\u001B[32m      4\u001B[39m \u001B[38;5;66;03m# each problem formulation has its own list of outcomes\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m dike_model, planning_steps = \u001B[43mget_model_for_problem_formulation\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m4\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/decision_making_assignments/final assignment EPA141/problem_formulation.py:59\u001B[39m, in \u001B[36mget_model_for_problem_formulation\u001B[39m\u001B[34m(problem_formulation_id)\u001B[39m\n\u001B[32m     37\u001B[39m def get_model_for_problem_formulation(problem_formulation_id):\n\u001B[32m     38\u001B[39m     \"\"\"Convenience function to prepare DikeNetwork in a way it can be input in the EMA-workbench.\n\u001B[32m     39\u001B[39m     Specify uncertainties, levers, and outcomes of interest.\n\u001B[32m     40\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m     57\u001B[39m \n\u001B[32m     58\u001B[39m     \"\"\"\n\u001B[32m---> \u001B[39m\u001B[32m59\u001B[39m     # Load the model:\n\u001B[32m     60\u001B[39m     function = DikeNetwork()\n\u001B[32m     61\u001B[39m     # workbench model:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/decision_making_assignments/final assignment EPA141/dike_model_function.py:32\u001B[39m, in \u001B[36mDikeNetwork.__init__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     29\u001B[39m \u001B[38;5;28mself\u001B[39m.num_events = \u001B[32m30\u001B[39m\n\u001B[32m     31\u001B[39m \u001B[38;5;66;03m# load network\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m32\u001B[39m G, dike_list, dike_branch, planning_steps = \u001B[43mfuns_generate_network\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_network\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     33\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mnum_planning_steps\u001B[49m\n\u001B[32m     34\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     36\u001B[39m \u001B[38;5;66;03m# Load hydrological statistics:\u001B[39;00m\n\u001B[32m     37\u001B[39m \u001B[38;5;28mself\u001B[39m.A = pd.read_excel(\u001B[33m\"\u001B[39m\u001B[33m./data/hydrology/werklijn_params.xlsx\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/decision_making_assignments/final assignment EPA141/funs_generate_network.py:91\u001B[39m, in \u001B[36mget_network\u001B[39m\u001B[34m(plann_steps_max)\u001B[39m\n\u001B[32m     88\u001B[39m     G.nodes[dike][\u001B[33m\"\u001B[39m\u001B[33mC3\u001B[39m\u001B[33m\"\u001B[39m] = Muskingum_params.loc[G.nodes[dike][\u001B[33m\"\u001B[39m\u001B[33mprec_node\u001B[39m\u001B[33m\"\u001B[39m], \u001B[33m\"\u001B[39m\u001B[33mC3\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m     90\u001B[39m \u001B[38;5;66;03m# The plausible 133 upstream wave-shapes:\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m91\u001B[39m G.nodes[\u001B[33m\"\u001B[39m\u001B[33mA.0\u001B[39m\u001B[33m\"\u001B[39m][\u001B[33m\"\u001B[39m\u001B[33mQevents_shape\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[43mpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread_excel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     92\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m./data/hydrology/wave_shapes.xls\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex_col\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0\u001B[39;49m\n\u001B[32m     93\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     95\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m G, dike_list, dike_branches, steps\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/decision_making_assignments/venv/lib/python3.13/site-packages/pandas/io/excel/_base.py:495\u001B[39m, in \u001B[36mread_excel\u001B[39m\u001B[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001B[39m\n\u001B[32m    493\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(io, ExcelFile):\n\u001B[32m    494\u001B[39m     should_close = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m495\u001B[39m     io = \u001B[43mExcelFile\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    496\u001B[39m \u001B[43m        \u001B[49m\u001B[43mio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    497\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    498\u001B[39m \u001B[43m        \u001B[49m\u001B[43mengine\u001B[49m\u001B[43m=\u001B[49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    499\u001B[39m \u001B[43m        \u001B[49m\u001B[43mengine_kwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mengine_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    500\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    501\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m engine \u001B[38;5;129;01mand\u001B[39;00m engine != io.engine:\n\u001B[32m    502\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    503\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mEngine should not be specified when passing \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    504\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33man ExcelFile - ExcelFile already has the engine set\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    505\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/decision_making_assignments/venv/lib/python3.13/site-packages/pandas/io/excel/_base.py:1567\u001B[39m, in \u001B[36mExcelFile.__init__\u001B[39m\u001B[34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001B[39m\n\u001B[32m   1564\u001B[39m \u001B[38;5;28mself\u001B[39m.engine = engine\n\u001B[32m   1565\u001B[39m \u001B[38;5;28mself\u001B[39m.storage_options = storage_options\n\u001B[32m-> \u001B[39m\u001B[32m1567\u001B[39m \u001B[38;5;28mself\u001B[39m._reader = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_engines\u001B[49m\u001B[43m[\u001B[49m\u001B[43mengine\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1568\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_io\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1569\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1570\u001B[39m \u001B[43m    \u001B[49m\u001B[43mengine_kwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mengine_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1571\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/decision_making_assignments/venv/lib/python3.13/site-packages/pandas/io/excel/_xlrd.py:45\u001B[39m, in \u001B[36mXlrdReader.__init__\u001B[39m\u001B[34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001B[39m\n\u001B[32m     33\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     34\u001B[39m \u001B[33;03mReader using xlrd engine.\u001B[39;00m\n\u001B[32m     35\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m     42\u001B[39m \u001B[33;03m    Arbitrary keyword arguments passed to excel engine.\u001B[39;00m\n\u001B[32m     43\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     44\u001B[39m err_msg = \u001B[33m\"\u001B[39m\u001B[33mInstall xlrd >= 2.0.1 for xls Excel support\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m45\u001B[39m \u001B[43mimport_optional_dependency\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mxlrd\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra\u001B[49m\u001B[43m=\u001B[49m\u001B[43merr_msg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     46\u001B[39m \u001B[38;5;28msuper\u001B[39m().\u001B[34m__init__\u001B[39m(\n\u001B[32m     47\u001B[39m     filepath_or_buffer,\n\u001B[32m     48\u001B[39m     storage_options=storage_options,\n\u001B[32m     49\u001B[39m     engine_kwargs=engine_kwargs,\n\u001B[32m     50\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/decision_making_assignments/venv/lib/python3.13/site-packages/pandas/compat/_optional.py:138\u001B[39m, in \u001B[36mimport_optional_dependency\u001B[39m\u001B[34m(name, extra, errors, min_version)\u001B[39m\n\u001B[32m    136\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[32m    137\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m errors == \u001B[33m\"\u001B[39m\u001B[33mraise\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m138\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(msg)\n\u001B[32m    139\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    141\u001B[39m \u001B[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001B[39;00m\n",
      "\u001B[31mImportError\u001B[39m: Missing optional dependency 'xlrd'. Install xlrd >= 2.0.1 for xls Excel support Use pip or conda to install xlrd."
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# enlisting uncertainties, their types (RealParameter/IntegerParameter/CategoricalParameter), lower boundary, and upper boundary\n",
    "import copy\n",
    "\n",
    "for unc in dike_model.uncertainties:\n",
    "    print(repr(unc))\n",
    "\n",
    "uncertainties = copy.deepcopy(dike_model.uncertainties)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# enlisting policy levers, their types (RealParameter/IntegerParameter), lower boundary, and upper boundary\n",
    "for policy in dike_model.levers:\n",
    "    print(repr(policy))\n",
    "\n",
    "levers = copy.deepcopy(dike_model.levers)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# enlisting outcomes\n",
    "for outcome in dike_model.outcomes:\n",
    "    print(repr(outcome))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# running the model through EMA workbench\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(scenarios=50, policies=4)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# observing the simulation runs\n",
    "experiments, outcomes = results\n",
    "print(outcomes.keys())\n",
    "experiments"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# only works because we have scalar outcomes\n",
    "#pd.DataFrame(outcomes)\n",
    "outcomes"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# defining specific policies\n",
    "# for example, policy 1 is about extra protection in upper boundary\n",
    "# policy 2 is about extra protection in lower boundary\n",
    "# policy 3 is extra protection in random locations\n",
    "\n",
    "\n",
    "def get_do_nothing_dict():\n",
    "    return {l.name: 0 for l in dike_model.levers}\n",
    "\n",
    "\n",
    "policies = [\n",
    "    Policy(\n",
    "        \"policy 1\",\n",
    "        **dict(\n",
    "            get_do_nothing_dict(),\n",
    "            **{\"0_RfR 0\": 1, \"0_RfR 1\": 1, \"0_RfR 2\": 1, \"A.1_DikeIncrease 0\": 5}\n",
    "        )\n",
    "    ),\n",
    "    Policy(\n",
    "        \"policy 2\",\n",
    "        **dict(\n",
    "            get_do_nothing_dict(),\n",
    "            **{\"4_RfR 0\": 1, \"4_RfR 1\": 1, \"4_RfR 2\": 1, \"A.5_DikeIncrease 0\": 5}\n",
    "        )\n",
    "    ),\n",
    "    Policy(\n",
    "        \"policy 3\",\n",
    "        **dict(\n",
    "            get_do_nothing_dict(),\n",
    "            **{\"1_RfR 0\": 1, \"2_RfR 1\": 1, \"3_RfR 2\": 1, \"A.3_DikeIncrease 0\": 5}\n",
    "        )\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# pass the policies list to EMA workbench experiment runs\n",
    "n_scenarios = 100\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(n_scenarios, policies)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "experiments, outcomes = results"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# only works because we have scalar outcomes\n",
    "pd.DataFrame(outcomes)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "GSA without Policies"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from ema_workbench import (\n",
    "    perform_experiments, Samplers, Policy\n",
    ")\n",
    "from ema_workbench.em_framework.salib_samplers import get_SALib_problem\n",
    "from SALib.analyze import sobol\n",
    "from problem_formulation import get_model_for_problem_formulation\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from ema_workbench import MultiprocessingEvaluator\n",
    "\n",
    "# Detect number of physical/logical cores\n",
    "import multiprocessing\n",
    "\n",
    "total_cores = multiprocessing.cpu_count()  # e.g., 16 logical cores for Ryzen 7700X\n",
    "desired_cores = total_cores // 2  # use 50% of your CPU (adjust as needed)\n",
    "\n",
    "N = 512  # Sobol sample base size\n",
    "with MultiprocessingEvaluator(model, n_processes=desired_cores) as evaluator:\n",
    "    experiments, outcomes = evaluator.perform_experiments(\n",
    "        scenarios=N,\n",
    "        policies=[zero_policy],\n",
    "        uncertainty_sampling=Samplers.SOBOL\n",
    "    )"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "outcomes"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from SALib.analyze import sobol\n",
    "from ema_workbench.em_framework.salib_samplers import get_SALib_problem\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Get the SALib problem setup\n",
    "problem = get_SALib_problem(model.uncertainties)\n",
    "expected_len = N * (len(problem['names']) + 2)\n",
    "\n",
    "# Step 2: Initialize result dictionaries\n",
    "sobol_results_mean = {}\n",
    "sobol_results_std = {}\n",
    "sobol_results_final = {}\n",
    "\n",
    "# Step 3: Loop through outcomes and apply reduction\n",
    "for outcome_name, values in outcomes.items():\n",
    "    arr = np.asarray(values)[:expected_len]\n",
    "\n",
    "    if arr.ndim == 1:\n",
    "        # Already scalar\n",
    "        y_mean = arr\n",
    "        y_std = np.zeros_like(arr)\n",
    "        y_final = arr\n",
    "    elif arr.ndim == 2:\n",
    "        # 2D array like (20480, 3)\n",
    "        y_mean = arr.mean(axis=1)\n",
    "        y_std = arr.std(axis=1)\n",
    "        y_final = arr[:, -1]\n",
    "    else:\n",
    "        print(f\"⚠️ Skipping unsupported shape: {outcome_name}, shape={arr.shape}\")\n",
    "        continue\n",
    "\n",
    "    # Run Sobol analysis for each reduction\n",
    "    sobol_results_mean[outcome_name] = sobol.analyze(problem, y_mean, calc_second_order=False)\n",
    "    sobol_results_std[outcome_name] = sobol.analyze(problem, y_std, calc_second_order=False)\n",
    "    sobol_results_final[outcome_name] = sobol.analyze(problem, y_final, calc_second_order=False)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Extract parameter names from the problem\n",
    "parameter_names = problem['names']\n",
    "\n",
    "# Convert a Sobol result dictionary into a tidy DataFrame\n",
    "def sobol_to_dataframe(sobol_dict, parameter_names, label):\n",
    "    records = []\n",
    "    for outcome_name, Si in sobol_dict.items():\n",
    "        for i, param in enumerate(parameter_names):\n",
    "            records.append({\n",
    "                'Outcome': outcome_name,\n",
    "                'Parameter': param,\n",
    "                'S1': Si['S1'][i],\n",
    "                'ST': Si['ST'][i],\n",
    "                'S1_conf': Si['S1_conf'][i],\n",
    "                'ST_conf': Si['ST_conf'][i],\n",
    "                'Reduction': label\n",
    "            })\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# Convert all three dictionaries to DataFrames\n",
    "df_mean = sobol_to_dataframe(sobol_results_mean, parameter_names, 'Mean')\n",
    "df_std = sobol_to_dataframe(sobol_results_std, parameter_names, 'Std')\n",
    "df_final = sobol_to_dataframe(sobol_results_final, parameter_names, 'Final')\n",
    "\n",
    "# Combine them all into one long-form DataFrame\n",
    "df_all = pd.concat([df_mean, df_std, df_final], ignore_index=True)\n",
    "\n",
    "# Plotting function for heatmaps\n",
    "def plot_sobol_heatmap(df, reduction_type):\n",
    "    pivot = df[df['Reduction'] == reduction_type].dropna(subset=[\"ST\"])\\\n",
    "        .pivot(index='Outcome', columns='Parameter', values='ST')\n",
    "\n",
    "    if pivot.empty:\n",
    "        print(f\"⚠️ No valid data to plot for reduction type: {reduction_type}\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(14, max(6, len(pivot) * 0.4)))\n",
    "    sns.heatmap(pivot, annot=True, fmt=\".2f\", cmap='YlGnBu', cbar_kws={'label': 'Total Sobol Index (ST)'})\n",
    "    plt.title(f\"Sobol ST Heatmap ({reduction_type})\")\n",
    "    plt.ylabel(\"Outcome\")\n",
    "    plt.xlabel(\"Input Parameter\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot all three heatmaps\n",
    "plot_sobol_heatmap(df_all, 'Mean')\n",
    "plot_sobol_heatmap(df_all, 'Std')\n",
    "plot_sobol_heatmap(df_all, 'Final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
